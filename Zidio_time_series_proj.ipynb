{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q prophet tensorflow plotly\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from prophet import Prophet\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from math import sqrt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Load and clean column names\n",
        "df = pd.read_csv('/content/Historic_stock_data.csv')\n",
        "df.columns = df.columns.str.strip()  # Remove leading/trailing whitespace\n",
        "\n",
        "# Check if 'Date' column exists\n",
        "if 'Date' not in df.columns:\n",
        "    raise KeyError(\"The dataset must contain a 'Date' column.\")\n",
        "\n",
        "# Parse dates\n",
        "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
        "df = df.dropna(subset=['Date'])\n",
        "df = df.sort_values('Date')\n",
        "df.set_index('Date', inplace=True)\n",
        "\n",
        "# Filter for 'Close' only\n",
        "df = df[['Close']]\n",
        "df = df.asfreq('B').fillna(method='ffill')\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(df['Close'])\n",
        "plt.title('Stock Closing Prices Over Time')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Close Price')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "result = adfuller(df['Close'])\n",
        "print(f\"ADF Statistic: {result[0]:.4f}\")\n",
        "print(f\"p-value: {result[1]:.4f}\")\n",
        "\n",
        "\n",
        "decomposition = seasonal_decompose(df['Close'], model='additive')\n",
        "decomposition.plot()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "forecast_steps = 30\n",
        "future_dates = pd.date_range(df.index[-1], periods=forecast_steps + 1, freq='B')[1:]\n",
        "\n",
        "arima_model = ARIMA(df['Close'], order=(5,1,0))\n",
        "arima_result = arima_model.fit()\n",
        "arima_pred = arima_result.forecast(steps=forecast_steps)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(df['Close'], label='Actual')\n",
        "plt.plot(future_dates, arima_pred, label='ARIMA Forecast')\n",
        "plt.legend()\n",
        "plt.title(\"ARIMA Forecast\")\n",
        "plt.show()\n",
        "\n",
        "# SARIMA Model\n",
        "sarima_model = SARIMAX(df['Close'], order=(1,1,1), seasonal_order=(1,1,1,12))\n",
        "sarima_result = sarima_model.fit()\n",
        "sarima_pred = sarima_result.forecast(forecast_steps)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(df['Close'], label='Actual')\n",
        "plt.plot(future_dates, sarima_pred, label='SARIMA Forecast')\n",
        "plt.legend()\n",
        "plt.title(\"SARIMA Forecast\")\n",
        "plt.show()\n",
        "\n",
        "#  Prophet Model\n",
        "df_prophet = df.reset_index().rename(columns={'Date': 'ds', 'Close': 'y'})\n",
        "prophet_model = Prophet(daily_seasonality=True)\n",
        "prophet_model.fit(df_prophet)\n",
        "future = prophet_model.make_future_dataframe(periods=forecast_steps)\n",
        "forecast = prophet_model.predict(future)\n",
        "\n",
        "# Plot\n",
        "prophet_model.plot(forecast)\n",
        "prophet_model.plot_components(forecast)\n",
        "\n",
        "#  LSTM Model\n",
        "data = df.values\n",
        "scaler = MinMaxScaler()\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "seq_len = 60\n",
        "X, y = [], []\n",
        "for i in range(seq_len, len(scaled_data)):\n",
        "    X.append(scaled_data[i-seq_len:i])\n",
        "    y.append(scaled_data[i])\n",
        "X, y = np.array(X), np.array(y)\n",
        "\n",
        "# Split data\n",
        "split = int(len(X) * 0.8)\n",
        "X_train, X_test = X[:split], X[split:]\n",
        "y_train, y_test = y[:split], y[split:]\n",
        "\n",
        "# Build LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, return_sequences=False, input_shape=(X_train.shape[1], 1)))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0)\n",
        "\n",
        "# Predict\n",
        "lstm_pred = model.predict(X_test)\n",
        "lstm_pred = scaler.inverse_transform(lstm_pred)\n",
        "y_test_actual = scaler.inverse_transform(y_test)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(y_test_actual, label='Actual')\n",
        "plt.plot(lstm_pred, label='LSTM Forecast')\n",
        "plt.legend()\n",
        "plt.title(\"LSTM Forecast\")\n",
        "plt.show()\n",
        "\n",
        "# Evaluation Metrics\n",
        "def evaluate_model(true, pred, name):\n",
        "    rmse = sqrt(mean_squared_error(true, pred))\n",
        "    mae = mean_absolute_error(true, pred)\n",
        "    mape = np.mean(np.abs((true - pred) / true)) * 100\n",
        "    print(f\"\\n{name} Evaluation:\")\n",
        "    print(f\"RMSE: {rmse:.4f}\")\n",
        "    print(f\"MAE : {mae:.4f}\")\n",
        "    print(f\"MAPE: {mape:.2f}%\")\n",
        "    return rmse, mae, mape\n",
        "\n",
        "# Slice ground truth\n",
        "truth = df['Close'][-forecast_steps:].values\n",
        "\n",
        "# Evaluate all models\n",
        "eval_results = {}\n",
        "eval_results['ARIMA'] = evaluate_model(truth, arima_pred, \"ARIMA\")\n",
        "eval_results['SARIMA'] = evaluate_model(truth, sarima_pred, \"SARIMA\")\n",
        "eval_results['Prophet'] = evaluate_model(truth, forecast['yhat'][-forecast_steps:].values, \"Prophet\")\n",
        "eval_results['LSTM'] = evaluate_model(y_test_actual[-forecast_steps:], lstm_pred[-forecast_steps:], \"LSTM\")\n",
        "\n",
        "# Compare All Models\n",
        "eval_df = pd.DataFrame(eval_results, index=['RMSE', 'MAE', 'MAPE (%)']).T\n",
        "print(\"\\nModel Comparison:\")\n",
        "print(eval_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "q2ELHeSig_Kb",
        "outputId": "d450a59f-24e4-49b3-c82a-d98ee7370b90"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/Historic_stock_data.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-393892105.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Load and clean column names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/Historic_stock_data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Remove leading/trailing whitespace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/Historic_stock_data.csv'"
          ]
        }
      ]
    }
  ]
}